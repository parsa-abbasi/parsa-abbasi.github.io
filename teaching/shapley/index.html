<!doctype html><html lang=en-us dir=ltr data-wc-theme-default=system><head><meta charset=utf-8><meta name=viewport content="width=device-width,initial-scale=1"><meta http-equiv=X-UA-Compatible content="IE=edge"><meta name=generator content="Hugo Blox Builder 0.3.1"><meta name=author content="Parsa Abbasi"><meta name=description content="An introduction to Shapley values and their applications in explaining ML models."><link rel=alternate hreflang=en-us href=https://parsa-abbasi.github.io/teaching/shapley/><link rel=stylesheet href=/css/themes/emerald.min.css><link href=/dist/wc.min.css rel=stylesheet><script>window.hbb={defaultTheme:document.documentElement.dataset.wcThemeDefault,setDarkTheme:()=>{document.documentElement.classList.add("dark"),document.documentElement.style.colorScheme="dark"},setLightTheme:()=>{document.documentElement.classList.remove("dark"),document.documentElement.style.colorScheme="light"}},console.debug(`Default Hugo Blox Builder theme is ${window.hbb.defaultTheme}`),"wc-color-theme"in localStorage?localStorage.getItem("wc-color-theme")==="dark"?window.hbb.setDarkTheme():window.hbb.setLightTheme():(window.hbb.defaultTheme==="dark"?window.hbb.setDarkTheme():window.hbb.setLightTheme(),window.hbb.defaultTheme==="system"&&(window.matchMedia("(prefers-color-scheme: dark)").matches?window.hbb.setDarkTheme():window.hbb.setLightTheme()))</script><script>document.addEventListener("DOMContentLoaded",function(){let e=document.querySelectorAll("li input[type='checkbox'][disabled]");e.forEach(e=>{e.parentElement.parentElement.classList.add("task-list")});const t=document.querySelectorAll(".task-list li");t.forEach(e=>{let t=Array.from(e.childNodes).filter(e=>e.nodeType===3&&e.textContent.trim().length>1);if(t.length>0){const n=document.createElement("label");t[0].after(n),n.appendChild(e.querySelector("input[type='checkbox']")),n.appendChild(t[0])}})})</script><link rel=icon type=image/png href=/media/icon_hu7118781151076284020.png><link rel=apple-touch-icon type=image/png href=/media/icon_hu5531948805957285787.png><link rel=canonical href=https://parsa-abbasi.github.io/teaching/shapley/><meta property="twitter:card" content="summary_large_image"><meta property="twitter:site" content="@ParsaAbbasi1996"><meta property="twitter:creator" content="@ParsaAbbasi1996"><meta property="og:site_name" content="Parsa Abbasi Personal Website"><meta property="og:url" content="https://parsa-abbasi.github.io/teaching/shapley/"><meta property="og:title" content="Understanding Shapley Values and SHAP | Parsa Abbasi Personal Website"><meta property="og:description" content="An introduction to Shapley values and their applications in explaining ML models."><meta property="og:image" content="https://parsa-abbasi.github.io/teaching/shapley/featured.jpg"><meta property="twitter:image" content="https://parsa-abbasi.github.io/teaching/shapley/featured.jpg"><meta property="og:locale" content="en-us"><meta property="article:published_time" content="2025-01-10T00:00:00+00:00"><meta property="article:modified_time" content="2025-01-10T00:00:00+00:00"><title>Understanding Shapley Values and SHAP | Parsa Abbasi Personal Website</title><style>@font-face{font-family:inter var;font-style:normal;font-weight:100 900;font-display:swap;src:url(/dist/font/Inter.var.woff2)format(woff2)}</style><link type=text/css rel=stylesheet href=/dist/pagefind/pagefind-ui.be766eb419317a14ec769d216e9779bfe8f3737c80e780f4ba0dafb57a41a482.css integrity="sha256-vnZutBkxehTsdp0hbpd5v+jzc3yA54D0ug2vtXpBpII="><script src=/dist/pagefind/pagefind-ui.87693d7c6f2b3b347ce359d0ede762c033419f0a32b22ce508c335a81d841f1b.js integrity="sha256-h2k9fG8rOzR841nQ7ediwDNBnwoysizlCMM1qB2EHxs="></script><script>window.hbb.pagefind={baseUrl:"/"}</script><style>html.dark{--pagefind-ui-primary:#eeeeee;--pagefind-ui-text:#eeeeee;--pagefind-ui-background:#152028;--pagefind-ui-border:#152028;--pagefind-ui-tag:#152028}</style><script>window.addEventListener("DOMContentLoaded",e=>{new PagefindUI({element:"#search",showSubResults:!0,baseUrl:window.hbb.pagefind.baseUrl,bundlePath:window.hbb.pagefind.baseUrl+"pagefind/"})}),document.addEventListener("DOMContentLoaded",()=>{let e=document.getElementById("search"),t=document.getElementById("search_toggle");t&&t.addEventListener("click",()=>{if(e.classList.toggle("hidden"),e.querySelector("input").value="",e.querySelector("input").focus(),!e.classList.contains("hidden")){let t=document.querySelector(".pagefind-ui__search-clear");t&&!t.hasAttribute("listenerOnClick")&&(t.setAttribute("listenerOnClick","true"),t.addEventListener("click",()=>{e.classList.toggle("hidden")}))}})})</script><link type=text/css rel=stylesheet href=/dist/lib/katex/katex.min.505d5f829022bb7b4f24dfee0aa1141cd7bba67afe411d1240335f820960b5c3.css integrity="sha256-UF1fgpAiu3tPJN/uCqEUHNe7pnr+QR0SQDNfgglgtcM="><script defer src=/dist/lib/katex/katex.min.dc84b296ec3e884de093158f760fd9d45b6c7abe58b5381557f4e138f46a58ae.js integrity="sha256-3ISyluw+iE3gkxWPdg/Z1Ftser5YtTgVV/ThOPRqWK4="></script><script defer src=/js/katex-renderer.6579ec9683211cfb952064aedf3a3baea5eeb17a061775b32b70917474637c80.js integrity="sha256-ZXnsloMhHPuVIGSu3zo7rqXusXoGF3WzK3CRdHRjfIA="></script><script defer src=/js/hugo-blox-en.min.8c8ea06bd0420f5067e52fa727b9f92303757322ba4431774153d59a9735eadb.js integrity="sha256-jI6ga9BCD1Bn5S+nJ7n5IwN1cyK6RDF3QVPVmpc16ts="></script><script async defer src=https://buttons.github.io/buttons.js></script></head><body class="dark:bg-hb-dark dark:text-white page-wrapper" id=top><div id=page-bg></div><div class="page-header sticky top-0 z-30"><header id=site-header class=header><nav class="navbar px-3 flex justify-left"><div class="order-0 h-100"><a class=navbar-brand href=/ title="Parsa Abbasi Personal Website">Parsa Abbasi</a></div><input id=nav-toggle type=checkbox class=hidden>
<label for=nav-toggle class="order-3 cursor-pointer flex items-center lg:hidden text-dark dark:text-white lg:order-1"><svg id="show-button" class="h-6 fill-current block" viewBox="0 0 20 20"><title>Open Menu</title><path d="M0 3h20v2H0V3zm0 6h20v2H0V9zm0 6h20v2H0V0z"/></svg><svg id="hide-button" class="h-6 fill-current hidden" viewBox="0 0 20 20"><title>Close Menu</title><polygon points="11 9 22 9 22 11 11 11 11 22 9 22 9 11 -2 11 -2 9 9 9 9 -2 11 -2" transform="rotate(45 10 10)"/></svg></label><ul id=nav-menu class="navbar-nav order-3 hidden lg:flex w-full pb-6 lg:order-1 lg:w-auto lg:space-x-2 lg:pb-0 xl:space-x-8 justify-left"><li class=nav-item><a class=nav-link href=/>Bio</a></li><li class=nav-item><a class=nav-link href=/experience/>Experience</a></li><li class=nav-item><a class=nav-link href=/#news>News</a></li><li class=nav-item><a class=nav-link href=/#talks>Talks</a></li><li class=nav-item><a class=nav-link href=/#papers>Papers</a></li><li class=nav-item><a class=nav-link href=/teaching/>Teaching</a></li><li class=nav-item><a class=nav-link href=/projects/>Projects</a></li></ul><div class="order-1 ml-auto flex items-center md:order-2 lg:ml-0"><button aria-label=search class="text-black hover:text-primary inline-block px-3 text-xl dark:text-white" id=search_toggle><svg height="16" width="16" viewBox="0 0 512 512" fill="currentcolor"><path d="M416 208c0 45.9-14.9 88.3-40 122.7L502.6 457.4c12.5 12.5 12.5 32.8.0 45.3s-32.8 12.5-45.3.0L330.7 376c-34.4 25.2-76.8 40-122.7 40C93.1 416 0 322.9.0 208S93.1.0 208 0 416 93.1 416 208zM208 352a144 144 0 100-288 144 144 0 100 288z"/></svg></button><div class="px-3 text-black hover:text-primary-700 dark:text-white dark:hover:text-primary-300
[&.active]:font-bold [&.active]:text-black/90 dark:[&.active]:text-white"><button class="theme-toggle mt-1" accesskey=t title=appearance><svg id="moon" width="24" height="18" viewBox="0 0 24 24" fill="none" stroke="currentcolor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="dark:hidden"><path d="M21 12.79A9 9 0 1111.21 3 7 7 0 0021 12.79z"/></svg><svg id="sun" width="24" height="18" viewBox="0 0 24 24" fill="none" stroke="currentcolor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="dark:block [&:not(dark)]:hidden"><circle cx="12" cy="12" r="5"/><line x1="12" y1="1" x2="12" y2="3"/><line x1="12" y1="21" x2="12" y2="23"/><line x1="4.22" y1="4.22" x2="5.64" y2="5.64"/><line x1="18.36" y1="18.36" x2="19.78" y2="19.78"/><line x1="1" y1="12" x2="3" y2="12"/><line x1="21" y1="12" x2="23" y2="12"/><line x1="4.22" y1="19.78" x2="5.64" y2="18.36"/><line x1="18.36" y1="5.64" x2="19.78" y2="4.22"/></svg></button></div></div></nav></header><div id=search class="hidden p-3"></div></div><div class="page-body my-10"><div class="mx-auto flex max-w-screen-xl"><div class="hb-sidebar-mobile-menu fixed inset-0 z-10 bg-white dark:bg-black/80 hidden"></div><aside class="hb-sidebar-container max-lg:[transform:translate3d(0,-100%,0)] lg:sticky"><div class="px-4 pt-4 lg:hidden"></div><div class="hb-scrollbar lg:h-[calc(100vh-var(--navbar-height))]"><ul class="flex flex-col gap-1 lg:hidden"><li class=open><a class="hb-sidebar-custom-link
text-gray-500 hover:bg-gray-100 hover:text-gray-900 dark:text-gray-300 dark:hover:bg-primary-800 dark:hover:text-gray-50" href=/teaching/>Teaching
<span data-hb-sidebar-toggle><svg fill="none" viewBox="0 0 24 24" stroke="currentcolor" class="h-[18px] min-w-[18px] rounded-sm p-0.5 hover:bg-gray-800/5 dark:hover:bg-gray-100/5"><path stroke-linecap="round" stroke-linejoin="round" stroke-width="2" d="M9 5l7 7-7 7" class="origin-center transition-transform rtl:-rotate-180"/></svg></span></a><div class="ltr:pr-0 overflow-hidden"><ul class=hb-sidebar-list><li class="flex flex-col open"><a class="hb-sidebar-custom-link
sidebar-active-item bg-primary-100 font-semibold text-primary-800 dark:bg-primary-300 dark:text-primary-900" href=/teaching/shapley/>Understanding Shapley Values and SHAP</a><ul class=hb-sidebar-mobile-toc><li><a href=#intuition class=hb-docs-link>Intuition</a></li><li><a href=#shapley-values class=hb-docs-link>Shapley Values</a></li><li><a href=#definitions class=hb-docs-link>Definitions</a></li><li><a href=#marginal-contribution-of-a-player class=hb-docs-link>Marginal Contribution of a Player</a></li><li><a href=#expected-marginal-contribution--shapley-value class=hb-docs-link>Expected Marginal Contribution / Shapley Value</a></li><li><a href=#axioms-of-shapley-values class=hb-docs-link>Axioms of Shapley Values</a></li><li><a href=#shapley-values-in-machine-learning class=hb-docs-link>Shapley Values in Machine Learning</a></li><li><a href=#shap class=hb-docs-link>SHAP</a></li><li><a href=#-resources class=hb-docs-link>üóÇÔ∏è Resources</a></li></ul></li><li class="flex flex-col"><a class="hb-sidebar-custom-link
text-gray-500 hover:bg-gray-100 hover:text-gray-900 dark:text-gray-300 dark:hover:bg-primary-800 dark:hover:text-gray-50" href=/teaching/nlp/>Natural Language Processing</a></li></ul></div></li><li><a class="hb-sidebar-custom-link
text-gray-500 hover:bg-gray-100 hover:text-gray-900 dark:text-gray-300 dark:hover:bg-primary-800 dark:hover:text-gray-50" href=/projects/>Projects</a></li><li><a class="hb-sidebar-custom-link
text-gray-500 hover:bg-gray-100 hover:text-gray-900 dark:text-gray-300 dark:hover:bg-primary-800 dark:hover:text-gray-50" href=/experience/>Experience</a></li><li><a class="hb-sidebar-custom-link
text-gray-500 hover:bg-gray-100 hover:text-gray-900 dark:text-gray-300 dark:hover:bg-primary-800 dark:hover:text-gray-50" href=/post/>Blog</a></li><li><a class="hb-sidebar-custom-link
text-gray-500 hover:bg-gray-100 hover:text-gray-900 dark:text-gray-300 dark:hover:bg-primary-800 dark:hover:text-gray-50" href=/publication/>Publications</a></li><li><a class="hb-sidebar-custom-link
text-gray-500 hover:bg-gray-100 hover:text-gray-900 dark:text-gray-300 dark:hover:bg-primary-800 dark:hover:text-gray-50" href=/event/>Recent & Upcoming Talks</a></li></ul><ul class="flex flex-col gap-1 max-lg:hidden"><li class=open><a class="hb-sidebar-custom-link
sidebar-active-item bg-primary-100 font-semibold text-primary-800 dark:bg-primary-300 dark:text-primary-900" href=/teaching/shapley/>Understanding Shapley Values and SHAP</a></li><li><a class="hb-sidebar-custom-link
text-gray-500 hover:bg-gray-100 hover:text-gray-900 dark:text-gray-300 dark:hover:bg-primary-800 dark:hover:text-gray-50" href=/teaching/nlp/>Natural Language Processing</a></li></ul></div></aside><nav class="hb-toc order-last hidden w-64 shrink-0 xl:block print:hidden px-4" aria-label="table of contents"><div class="hb-scrollbar text-sm [hyphens:auto] sticky top-16 overflow-y-auto pr-4 pt-6 max-h-[calc(100vh-var(--navbar-height)-env(safe-area-inset-bottom))] -mr-4 rtl:-ml-4"><p class="mb-4 font-semibold tracking-tight">On this page</p><ul><li class="my-2 scroll-my-6 scroll-py-6"><a class="font-semibold inline-block text-gray-500 hover:text-gray-900 dark:text-gray-400 dark:hover:text-gray-300 w-full break-words" href=#intuition>Intuition</a></li><li class="my-2 scroll-my-6 scroll-py-6"><a class="font-semibold inline-block text-gray-500 hover:text-gray-900 dark:text-gray-400 dark:hover:text-gray-300 w-full break-words" href=#shapley-values>Shapley Values</a></li><li class="my-2 scroll-my-6 scroll-py-6"><a class="pl-4 rtl:pr-4 inline-block text-gray-500 hover:text-gray-900 dark:text-gray-400 dark:hover:text-gray-300 w-full break-words" href=#example>Example</a></li><li class="my-2 scroll-my-6 scroll-py-6"><a class="font-semibold inline-block text-gray-500 hover:text-gray-900 dark:text-gray-400 dark:hover:text-gray-300 w-full break-words" href=#definitions>Definitions</a></li><li class="my-2 scroll-my-6 scroll-py-6"><a class="font-semibold inline-block text-gray-500 hover:text-gray-900 dark:text-gray-400 dark:hover:text-gray-300 w-full break-words" href=#marginal-contribution-of-a-player>Marginal Contribution of a Player</a></li><li class="my-2 scroll-my-6 scroll-py-6"><a class="font-semibold inline-block text-gray-500 hover:text-gray-900 dark:text-gray-400 dark:hover:text-gray-300 w-full break-words" href=#expected-marginal-contribution--shapley-value>Expected Marginal Contribution / Shapley Value</a></li><li class="my-2 scroll-my-6 scroll-py-6"><a class="font-semibold inline-block text-gray-500 hover:text-gray-900 dark:text-gray-400 dark:hover:text-gray-300 w-full break-words" href=#axioms-of-shapley-values>Axioms of Shapley Values</a></li><li class="my-2 scroll-my-6 scroll-py-6"><a class="pl-4 rtl:pr-4 inline-block text-gray-500 hover:text-gray-900 dark:text-gray-400 dark:hover:text-gray-300 w-full break-words" href=#-efficiency>üéØ Efficiency</a></li><li class="my-2 scroll-my-6 scroll-py-6"><a class="pl-4 rtl:pr-4 inline-block text-gray-500 hover:text-gray-900 dark:text-gray-400 dark:hover:text-gray-300 w-full break-words" href=#-symmetry>‚öñÔ∏è Symmetry</a></li><li class="my-2 scroll-my-6 scroll-py-6"><a class="pl-4 rtl:pr-4 inline-block text-gray-500 hover:text-gray-900 dark:text-gray-400 dark:hover:text-gray-300 w-full break-words" href=#-dummynull-player>‚≠ï Dummy/Null Player</a></li><li class="my-2 scroll-my-6 scroll-py-6"><a class="pl-4 rtl:pr-4 inline-block text-gray-500 hover:text-gray-900 dark:text-gray-400 dark:hover:text-gray-300 w-full break-words" href=#-additivity>‚ûï Additivity</a></li><li class="my-2 scroll-my-6 scroll-py-6"><a class="font-semibold inline-block text-gray-500 hover:text-gray-900 dark:text-gray-400 dark:hover:text-gray-300 w-full break-words" href=#shapley-values-in-machine-learning>Shapley Values in Machine Learning</a></li><li class="my-2 scroll-my-6 scroll-py-6"><a class="pl-4 rtl:pr-4 inline-block text-gray-500 hover:text-gray-900 dark:text-gray-400 dark:hover:text-gray-300 w-full break-words" href=#explainer-model>Explainer Model</a></li><li class="my-2 scroll-my-6 scroll-py-6"><a class="pl-4 rtl:pr-4 inline-block text-gray-500 hover:text-gray-900 dark:text-gray-400 dark:hover:text-gray-300 w-full break-words" href=#additive-feature-attribution-method>Additive Feature Attribution Method</a></li><li class="my-2 scroll-my-6 scroll-py-6"><a class="font-semibold inline-block text-gray-500 hover:text-gray-900 dark:text-gray-400 dark:hover:text-gray-300 w-full break-words" href=#shap>SHAP</a></li><li class="my-2 scroll-my-6 scroll-py-6"><a class="pl-4 rtl:pr-4 inline-block text-gray-500 hover:text-gray-900 dark:text-gray-400 dark:hover:text-gray-300 w-full break-words" href=#linear-shap-without-dependence>Linear SHAP (without dependence)</a></li><li class="my-2 scroll-my-6 scroll-py-6"><a class="pl-4 rtl:pr-4 inline-block text-gray-500 hover:text-gray-900 dark:text-gray-400 dark:hover:text-gray-300 w-full break-words" href=#linear-shap-with-dependence>Linear SHAP (with dependence)</a></li><li class="my-2 scroll-my-6 scroll-py-6"><a class="pl-4 rtl:pr-4 inline-block text-gray-500 hover:text-gray-900 dark:text-gray-400 dark:hover:text-gray-300 w-full break-words" href=#kernel-shap>Kernel SHAP</a></li><li class="my-2 scroll-my-6 scroll-py-6"><a class="pl-4 rtl:pr-4 inline-block text-gray-500 hover:text-gray-900 dark:text-gray-400 dark:hover:text-gray-300 w-full break-words" href=#tree-shap>Tree SHAP</a></li><li class="my-2 scroll-my-6 scroll-py-6"><a class="font-semibold inline-block text-gray-500 hover:text-gray-900 dark:text-gray-400 dark:hover:text-gray-300 w-full break-words" href=#-resources>üóÇÔ∏è Resources</a></li><li class="my-2 scroll-my-6 scroll-py-6"><a class="pl-4 rtl:pr-4 inline-block text-gray-500 hover:text-gray-900 dark:text-gray-400 dark:hover:text-gray-300 w-full break-words" href=#-blog-posts>üì∞ Blog Posts</a></li><li class="my-2 scroll-my-6 scroll-py-6"><a class="pl-4 rtl:pr-4 inline-block text-gray-500 hover:text-gray-900 dark:text-gray-400 dark:hover:text-gray-300 w-full break-words" href=#-videos>üéûÔ∏è Videos</a></li><li class="my-2 scroll-my-6 scroll-py-6"><a class="pl-4 rtl:pr-4 inline-block text-gray-500 hover:text-gray-900 dark:text-gray-400 dark:hover:text-gray-300 w-full break-words" href=#-coding>üë®‚Äçüíª Coding</a></li></ul>
    
    
  </div></nav><article class="flex w-full min-w-0 min-h-[calc(100vh-var(--navbar-height))] justify-center break-words pb-8 pr-[calc(env(safe-area-inset-right)-1.5rem)]"><main class="prose prose-slate lg:prose-xl dark:prose-invert w-full min-w-0 max-w-6xl px-6 pt-4 md:px-12"><div class=mb-1><div class="mt-1.5 flex items-center gap-1 overflow-hidden text-sm text-gray-500 dark:text-gray-400"><div class="whitespace-nowrap transition-colors min-w-[24px] overflow-hidden text-ellipsis hover:text-gray-900 dark:hover:text-gray-100"><a href=https://parsa-abbasi.github.io/teaching/>Teaching</a></div><svg class="w-3.5 shrink-0" viewBox="0 0 24 24"><path fill="none" stroke="currentcolor" stroke-linecap="round" stroke-linejoin="round" stroke-width="1.5" d="m8.25 4.5 7.5 7.5-7.5 7.5"/></svg><div class="whitespace-nowrap font-medium text-gray-700 dark:text-gray-100">Understanding Shapley Values and SHAP</div></div></div><div class="content text-base"><h1>Understanding Shapley Values and SHAP</h1><p>SHAP (SHapley Additive exPlanations) is a unified approach to explain the output of any machine learning model. In other words, it is a model-agnostic method that considers the model as a black box and only access the input and output of the model. It tries to explain the output of the model for a specific instance by computing the contribution of each component of the input to the output. The components can be features/columns in a tabular dataset, a set of pixels in an image, a word/token in a text document, etc. In this article, we first introduce the concept of Shapley values and then explain how SHAP uses Shapley values to explain the predictions of machine learning models.</p><h2 id=intuition>Intuition</h2><p>To be honest, &ldquo;Shapley Values&rdquo; is a term that I have been hearing a lot in the literature, but I was afraid to dive into it because it sounded too complex and there wasn&rsquo;t a straightforward explanation of what it is and how it works. Recently, my supervisor shared me an article from <a href=https://towardsdatascience.com/introduction-to-shap-values-and-their-application-in-machine-learning-8003718e6827 target=_blank rel=noopener>Towards Data Science</a> that explained Shapley values comprehensively and I thought it was time to understand what Shapley values are, once and for all! However, the article was too long (around 120 pages in a PDF format) and I think many people would be discouraged to read it. So, I decided to write a blog post to summarize the key concepts which I learned from until now and share a more straightforward explanation of Shapley values. My explanation may not be as comprehensive (or even accurate) as the original article, but I will try to make it as simple as possible to allow everyone to easily understand this great concept.</p><h2 id=shapley-values>Shapley Values</h2><p>To understand how Shapley values can explain the predictions of a machine learning model, we first need to understand the concept of <a href=https://en.wikipedia.org/wiki/Shapley_value target=_blank rel=noopener>Shapley values</a> which come from <a href=https://en.wikipedia.org/wiki/Cooperative_game_theory target=_blank rel=noopener><em>cooperative game theory</em></a>. This mathematical concept introduced by <a href=https://en.wikipedia.org/wiki/Lloyd_Shapley target=_blank rel=noopener><em>Lloyd Shapley</em></a> in 1953 (and he was awarded the <em>Nobel Prize</em> in <em>Economic Sciences</em> in 2012 for this work) is used to fairly distribute the total gains of a coalition of players in a cooperative game among the players. What do we mean by &ldquo;coalition of players&rdquo; and &ldquo;cooperative game&rdquo;? Let&rsquo;s break it down with an example.</p><h3 id=example>Example</h3><p>Imagine that you gathered some of your friends to record an album together. Some of them are good at playing an instrument, some in singing, some in mixing, some may be helpful in providing recording equipment, marketing, etc. Each of them has a different role in the process of recording and releasing the album. When the album is released, it will generate some revenue. Let&rsquo;s say that the album is a hit and it generates ‚Ç¨100,000 in revenue. Now, the question is: how should we distribute this revenue among the friends who contributed to the album? Yes, you can distribute it equally among all friends, but is it fair? Should the friend who played the drums get the same share as the friend who provided the recording equipment? Each friend had an impact on the success of the album, but their contributions are different. This is where Shapley values come into play.</p><h2 id=definitions>Definitions</h2><p>Imagine we have $M$ playes (numbered from 1 to $M$) and let $F$ be the set of all players ($F = \{1, 2, \ldots, M\}$). A <strong>coalition</strong> is a subset of players $S \subseteq F$ which can be any combination of players. The set $F$ itself is also a coalition, which commonly referred to as the <strong>grand coalition</strong>. We can have $2^M$ possible coalitions in total (the empty set $\emptyset$ is also a coalition that has no players).</p><p>The <strong>worth</strong> of a coalition is a real number that represents the total gains that the coalition can achieve and it is denoted by $v(S)$ for a coalition $S$. Note that $v$ is a function that takes a coalition as input and returns a real number as output, and commonly referred to as the <strong>characteristic function</strong> of the game. The worth of the grand coalition is the total gains that all players can achieve together, i.e., $v(F)$. The worth of the empty set is zero, i.e., $v(\emptyset) = 0$. The worth of a coalition can be calculated in different ways depending on the game. For example, in our album example, the worth of a coalition can be the revenue generated by the album when the friends in the coalition work together.</p><h2 id=marginal-contribution-of-a-player>Marginal Contribution of a Player</h2><p>Now the question is how we can compute the contribution of a player to the total gains of a coalition. Suppose that we have the following table and we assigned a number to each player.</p><table><thead><tr><th style=text-align:center>Player Name</th><th style=text-align:center>Player Number</th></tr></thead><tbody><tr><td style=text-align:center>$Thom$</td><td style=text-align:center>$1$</td></tr><tr><td style=text-align:center>$Colin$</td><td style=text-align:center>$2$</td></tr><tr><td style=text-align:center>$Jonny$</td><td style=text-align:center>$3$</td></tr><tr><td style=text-align:center>$Ed$</td><td style=text-align:center>$4$</td></tr><tr><td style=text-align:center>$Phil$</td><td style=text-align:center>$5$</td></tr><tr><td style=text-align:center>$Nigel$</td><td style=text-align:center>$6$</td></tr></tbody></table><p>Let&rsquo;s say we start with the empty set and add players one by one to form a coalition until we reach the grand coalition. For example, we can start with the empty set $\emptyset$ and add $Thom$ to form the coalition $\{1\}$, then add $Colin$ to form the coalition $\{1, 2\}$, and we continue this process until we reach the grand coalition $\{1, 2, 3, 4, 5, 6\}$. The total gain increases as we add more players to the coalition. Suppose the current coalition is ${1, 2, 3}$ and we want to add player $4$ to the coalition. Now, what is the marginal contribution of player $4$ to the total gains of the coalition $\{1, 2, 3, 4\}$? We can simply calculate the total gains of the coalition $\{1, 2, 3, 4\}$ and subtract the total gains of the coalition $\{1, 2, 3\}$ from it. This difference is the contribution of player $4$.</p>$$ \text{Marginal Contribution of Player 4} = v(\{1, 2, 3, 4\}) - v(\{1, 2, 3\}) $$<div class="flex px-4 py-3 mb-6 rounded-md bg-primary-100 dark:bg-primary-900"><span class="pr-3 pt-1 text-primary-600 dark:text-primary-300"><svg height="24" viewBox="0 0 24 24"><path fill="none" stroke="currentcolor" stroke-linecap="round" stroke-linejoin="round" stroke-width="1.5" d="m11.25 11.25.041-.02a.75.75.0 011.063.852l-.708 2.836a.75.75.0 001.063.853l.041-.021M21 12A9 9 0 113 12a9 9 0 0118 0m-9-3.75h.008v.008H12z"/></svg>
</span><span class=dark:text-neutral-300>Order of adding players to the coalition is important! Suppose $Thom$ ($1$) have started the band and recorded some songs. However, when $Colin$ ($2$) joined the band, they re-recorded some songs and their revenue increased by ‚Ç¨10,000 (which is the contribution of $Colin$). Now, when $Jonny$ ($3$) joined the band, they re-recorded some songs again and their revenue increased by just ‚Ç¨2,000. However, $Jonny$ feels unfair when comparing his contribution to $Colin$&rsquo;s contribution. He believes that if he had joined the band before $Colin$, the revenue would have also increased by ‚Ç¨10,000. So, we need to consider all possible orders of adding players to the coalition to calculate the contribution of a player fairly.</span></div><h2 id=expected-marginal-contribution--shapley-value>Expected Marginal Contribution / Shapley Value</h2><p>We&rsquo;ve seen how we can calculate the contribution of a player to the total gains of a specific coalition. However, as we mentioned earlier, the contribution of a player depends on the order of adding players to the coalition and we need to consider all possible orders. To do this, we compute the marginal contribution of a player for all possible permutations of players ($F$) and take the average of these contributions. This <strong>Expected Marginal Contribution</strong> is called the <strong>Shapley value</strong> of the player. As we will have $|F|!$ permutations in total, the Shapley value of player $i$, denoted by $\phi_i$, can be calculated as follows:</p>$$ \phi_i = \frac{1}{|F|!} \sum_{p \in P} \left( v(S \cup \{i\}) - v(S) \right) $$<p>In this formula, $P$ is the set of all permutations of players, and $S$ is the coalition related to the permutation $p \in P$. The following table shows how we can calculate the Shapley value of player $4$ for each permutation of players.</p><table><thead><tr><th style=text-align:center>Permutation</th><th style=text-align:center>Marginal Contribution of Player 4</th></tr></thead><tbody><tr><td style=text-align:center>$[1, 2, 3, 4, 5, 6]$</td><td style=text-align:center>$v(\{1, 2, 3, 4\}) - v(\{1, 2, 3\})$</td></tr><tr><td style=text-align:center>$[2, 1, 3, 4, 5, 6]$</td><td style=text-align:center>$v(\{1, 2, 3, 4\}) - v(\{1, 2, 3\})$</td></tr><tr><td style=text-align:center>$[3, 2, 1, 4, 5, 6]$</td><td style=text-align:center>$v(\{1, 2, 3, 4\}) - v(\{1, 2, 3\})$</td></tr><tr><td style=text-align:center>$\vdots$</td><td style=text-align:center>$\vdots$</td></tr><tr><td style=text-align:center>$[4, 1, 2, 3, 5, 6]$</td><td style=text-align:center>$v(\{4\}) - v(\emptyset)$</td></tr><tr><td style=text-align:center>$\vdots$</td><td style=text-align:center>$\vdots$</td></tr><tr><td style=text-align:center>$[6, 5, 4, 3, 2, 1]$</td><td style=text-align:center>$v(\{4, 5, 6\}) - v(\{5, 6\})$</td></tr></tbody></table><div class="flex px-4 py-3 mb-6 rounded-md bg-primary-100 dark:bg-primary-900"><span class="pr-3 pt-1 text-primary-600 dark:text-primary-300"><svg height="24" viewBox="0 0 24 24"><path fill="none" stroke="currentcolor" stroke-linecap="round" stroke-linejoin="round" stroke-width="1.5" d="m11.25 11.25.041-.02a.75.75.0 011.063.852l-.708 2.836a.75.75.0 001.063.853l.041-.021M21 12A9 9 0 113 12a9 9 0 0118 0m-9-3.75h.008v.008H12z"/></svg>
</span><span class=dark:text-neutral-300>The characteristic function $v$ takes a coalition/set as input, not a permutation. This is because the worth of a coalition is independent of the order of players in the coalition. The worth of the coalition of $Thom$ and $Colin$ is the same as the coalition of $Colin$ and $Thom$.</span></div><p>Now, we take the average of these contributions to calculate the Shapley value of player $4$. As we can see, some permutations have the same marginal contribution since their coalitions are the same. So, why don&rsquo;t we make it simpler and only calculate the distinct values of contributions and multiply them by the number of times they have been repeated in the permutations?</p><p>To do this, we need to find how many permutations can be formed from each coalition. If you look at the table above, you can see that the term $v(\{1, 2, 3, 4\}) - v(\{1, 2, 3\})$ is repeated for all permutations that the player $4$ is added after the players $1$, $2$, and $3$. So, if $S=\{1, 2, 3\}$, the player $4$ can be added after theses players in $|S|! = 3! = 6$ different ways. Furthermore, the remaining players can be added to the coalition in $(|F|-|S|-1)! = (6-3-1)! = 2!$ different ways. So, the Shapley value of player $4$ can be calculated as follows:</p>$$ \phi_i = \sum_{S \subseteq F \setminus \{i\}} \frac{|S|! \cdot (|F|-|S|-1)!}{|F|!} \left( v(S \cup \{i\}) - v(S) \right) $$<h2 id=axioms-of-shapley-values>Axioms of Shapley Values</h2><p>Shapley values have some provable properties that make them unique and fair. This is because of these <em>axioms</em> that Shapley values are mathematically strong and widely accepted. The axioms of Shapley values are as follows:</p><h3 id=-efficiency>üéØ Efficiency</h3><p>The sum of Shapley values of all players should be equal to the total gains of the grand coalition. In other words, if we sum the Shapley values of all players, it should be equal to the worth of the case where all players work together.</p>$$ \sum_{i=1}^{|F|} \phi_i = v(F) $$<h3 id=-symmetry>‚öñÔ∏è Symmetry</h3><p>If two players have the same contribution to every possible coalition, their Shapley values should be the same.</p>$$ \text{If } v(S \cup \{i\}) = v(S \cup \{j\}) \text{ for all } S \subseteq F \setminus \{i, j\}, \text{ then } \phi_i = \phi_j $$<h3 id=-dummynull-player>‚≠ï Dummy/Null Player</h3><p>If a player has no contribution to any coalition, its Shapley value should be zero.</p>$$ \text{If } v(S \cup \{i\}) = v(S) \text{ for all } S \subseteq F \setminus \{i\}, \text{ then } \phi_i = 0 $$<h3 id=-additivity>‚ûï Additivity</h3><p>If we have two games (or two characteristic functions) and we calculate the Shapley values of players for each game separately, the Shapley value of a player in the combined game should be the sum of the Shapley values of the player in each game. This axiom is based on the assumption that any game played are independent of each other.</p>$$ \phi_i(u+v) = \phi_i(u) + \phi_i(v) $$<h2 id=shapley-values-in-machine-learning>Shapley Values in Machine Learning</h2><p>Now, let&rsquo;s see how Shapley values can be used to explain the predictions of machine learning models.
Suppose we have a training tabular dataset with $N$ samples and $M$ features. The following table shows the features ($X_1, X_2, \ldots, X_M$) and the target variable ($y$) of the dataset.</p><table><thead><tr><th style=text-align:center>$X_1$</th><th style=text-align:center>$X_2$</th><th style=text-align:center>$\ldots$</th><th style=text-align:center>$X_M$</th><th style=text-align:center>$y$</th></tr></thead><tbody><tr><td style=text-align:center>$x_1^{(1)}$</td><td style=text-align:center>$x_2^{(1)}$</td><td style=text-align:center>$\ldots$</td><td style=text-align:center>$x_M^{(1)}$</td><td style=text-align:center>$y^{(1)}$</td></tr><tr><td style=text-align:center>$x_1^{(2)}$</td><td style=text-align:center>$x_2^{(2)}$</td><td style=text-align:center>$\ldots$</td><td style=text-align:center>$x_M^{(2)}$</td><td style=text-align:center>$y^{(2)}$</td></tr><tr><td style=text-align:center>$\vdots$</td><td style=text-align:center>$\vdots$</td><td style=text-align:center>$\vdots$</td><td style=text-align:center>$\vdots$</td><td style=text-align:center>$\vdots$</td></tr><tr><td style=text-align:center>$x_1^{(N)}$</td><td style=text-align:center>$x_2^{(N)}$</td><td style=text-align:center>$\ldots$</td><td style=text-align:center>$x_M^{(N)}$</td><td style=text-align:center>$y^{(N)}$</td></tr></tbody></table><p>We train a model ($f$) on this dataset and we want to explain the prediction of the model for a specific sample ($x$). The model/function $f$ takes the input sample $x$ and returns the output $f(x)$. By comparing $f(x)$ with the true target value $y$, we can calculate the prediction error of the model for the sample $x$. The question is: how can we explain the prediction of the model for the sample $x$? Which features of the sample $x$ have the most impact on the prediction of the model? This is where Shapley values come into play.</p><p>We can consider the model as a cooperative game where the players are the $M$ features. However, what should be the worth of a coalition in this game? We can define it using the $f(x)$ with a slight modification.
As you may remember, the characteristic function $v$ should output $0$ when the coalition is empty. But how can the model predict the output when there are no features in the coalition? Most of the ML models doesn&rsquo;t support <code>NA</code> values, so we need to modify the characteristic function to handle this case. We can use a sample of training data (or all of them) and take the average of the predictions of the model for these samples as our best guess. Suppose we have a sample of $k \leq N$ samples, our prediction when we have no features in the coalition can be calculated as follows:</p>$$ f(x) = f(\text{NA}, \text{NA}, \ldots, \text{NA}) = \frac{1}{k} \sum_{i=1}^k f(x^{(i)}) $$<p>Now, we can define the characteristic function $v$ as follows:</p>$$ v(F) = v({X_1, X_2, \ldots, X_M}) = f(x) - E[f(x)] = f(x) - \frac{1}{k} \sum_{i=1}^k f(x^{(i)}) $$<p>$E(f(x))$ is the expected value of the model&rsquo;s prediction when we have no features in the coalition. The worth of the grand coalition is the difference between the model&rsquo;s prediction for the sample $x$ and the average prediction of the model for the samples in the training dataset. The worth of the empty set is zero, i.e., $v(\emptyset) = 0$ (as $f(x) = E[f(x)]$ when we have no features).</p><p>How can we apply the model to a subset of its original features (a coalition)? For example, if we have the coalition $S=\{X_{s1}, X_{s2}, \ldots, X_{sp}\}$, we need the marginal value of $f$ for these features which is called $f_S(x_S)$.</p>$$ f_S(x_S) = f_S(x_{s1}, x_{s2}, \ldots, x_{sp}) $$<p>There is two possible ways to do this:</p><ol><li>We can retrain the same type of model on the features present in the coalition $S$</li><li>We can use the original model $f$ to calculate $f_S$ $\rightarrow$ Replace the features which are not available with <code>NA</code> values</li></ol><p>Let&rsquo;s assume that the model accepts <code>NA</code> values and see how the Shapley values can be calculated, then discuss how we can handle the case when the model doesn&rsquo;t support <code>NA</code> values. The worth of the coalition $S$ can be calculated as follows:</p>$$ v(S) = v(\{x_{s1}, x_{s2}, \ldots, x_{sp}\}) = f_S(x_S) - E[f(x)] $$<p>To calculate the Shapley value of the feature $X_i$, we need to consider all possible permutations of features and calculate the marginal contribution of the feature $X_i$ for each permutation. The Shapley value of the feature $X_i$ can be calculated as follows:</p>$$ \phi_i = \sum_{S \subseteq F \setminus \{i\}} \frac{|S|! \cdot (|F|-|S|-1)!}{|F|!} \left( f_{S\cup \{i\}}(x_{S \cup \{i\}}) - E[f(x)] - (f_S(x_S) - E[f(x)] \right) $$$$ \phi_i = \sum_{S \subseteq F \setminus \{i\}} \frac{|S|! \cdot (|F|-|S|-1)!}{|F|!} \left( f_{S\cup \{i\}}(x_{S \cup \{i\}}) - f_S(x_S) \right) $$<div class=highlight><pre tabindex=0 class=chroma><code class=language-markdown data-lang=markdown><span class=line><span class=cl>{{<span class=p>&lt;</span> <span class=nt>spoiler</span> <span class=na>text</span><span class=o>=</span><span class=s>&#34;üëâ Click to view the solution&#34;</span> <span class=p>&gt;</span>}}
</span></span><span class=line><span class=cl>You found me!
</span></span><span class=line><span class=cl>{{<span class=p>&lt;</span> <span class=p>/</span><span class=nt>spoiler</span> <span class=p>&gt;</span>}}
</span></span></code></pre></div><p>renders as</p><details class=spoiler id=spoiler-2><summary class=cursor-pointer>üëâ Click to view the solution</summary><div class="rounded-lg bg-neutral-50 dark:bg-neutral-800 p-2">You found me üéâ</div></details><div class=highlight><pre tabindex=0 class=chroma><code class=language-markdown data-lang=markdown><span class=line><span class=cl>{{<span class=p>&lt;</span> <span class=nt>spoiler</span> <span class=na>text</span><span class=o>=</span><span class=s>&#34;üéØ Efficiency Property&#34;</span> <span class=p>&gt;</span>}}
</span></span><span class=line><span class=cl>If we use the efficiency property of Shapley values, we&#39;ll find out that the sum of Shapley values of all features should be equal to the difference between the model&#39;s prediction for the sample $x$ and the average prediction of the model for the samples in the training dataset.
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>$$ \sum_{i=1}^{|F|} \phi_i = v(F) = f(x) - E[f(x)] $$
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>{{<span class=p>&lt;</span> <span class=p>/</span><span class=nt>spoiler</span> <span class=p>&gt;</span>}}
</span></span></code></pre></div><h3 id=explainer-model>Explainer Model</h3><p>As we are moving towards answering the question of how we can calculate and use Shapley values to explain the predictions of machine learning models, we need to discuss the concept of the <strong>explainer model</strong> and formulate it. The explainer ($g$) is an interpretable model that takes $|F| = M$ binary variables as a vector input ($z'$).</p>$$ g(z') = g(z'_1, z'_2, \ldots, z'_M) \quad z'_i \in \{0, 1\} $$<p>The coalition vector $z'$ represents a coalition of the available values of $x$. Those elements that are <code>NA</code> in the original sample $x$ are replaced with $0$ in the vector $z'$ and the rest of the elements are replaced with $0$ or $1$. For example, suppose we have five features and the second feature for a given sample is <code>NA</code>:</p>$$ x = [x_1, NA, x_3, x_4, x_5] $$<p>We can define $x'$ as a <em>simplified input features</em> to show if a feature is present or not in the sample $x$:</p>$$ x' = [1, 0, 1, 1, 1] $$<p>Furthermore, assume that there is a mapping function $h_x$ that maps the coalition vector $x'$ to the original sample $x$:</p>$$ h_x(x') = x$$<p>Now, we can define any coalition vector $z'$. For example, the following coalition vector represents the coalition $S = \{X_1, X_3, X_4\}$:</p>$$ z' = [1, 0, 1, 1, 0] $$$$ z = h_x(z') = [x_1, NA, x_3, x_4, NA] $$<p>We want the prediction of $f$ for $z$ to be as close as possible to the prediction of $g$ for $z'$:</p>$$ g(z') \approx f(h_x(z')) \quad \text{whenever} \enspace z' \approx x' $$<h3 id=additive-feature-attribution-method>Additive Feature Attribution Method</h3><p>We can classify the explaination methods based on $g$. For instance, if $g$ is a linear model, we call it <em>Additive Feature Attribution Method</em>. Suppose $c_i$ are some constants, then the prediction of $g$ can be calculated as follows:</p>$$ g(z') = \phi_0 + \phi_1 z'_1 + \phi_2 z'_2 + \ldots + \phi_M z'_M = \phi_0 + \sum_{i=1}^M \phi_i z'_i $$<p>We can compute the Shapley values as follows:</p>$$ \phi_i(f,x) = \sum_{z' \subseteq x'} \frac{|z' - 1|! \cdot (|x'|-|z'|)!}{|x'|!} \left( f_x(z') - f_x(z' \setminus \{i\}) \right) $$<p>Note that the $\phi_0$ is the average prediction of the model for the samples in the training dataset ($E[f(x)]$).</p><p>As model $g$ can mimic $f$ perfectly for a single prediction ($f(X)$) and is linear (therefore, interpretable), we can use it as an explainer model for $f$.</p><h2 id=shap>SHAP</h2><p>In the above section, we assumed that the model $f$ can handle <code>NA</code> values and we can calculate the Shapley values directly. However, in practice most of the machine learning models don&rsquo;t support <code>NA</code> values and we need to find a way to calculate the Shapley values without using <code>NA</code> values. <strong>SHAP (SHapley Additive exPlanations)</strong> is an additive feature attribution method which proposes to use a conditional probability distribution to estimate the Shapley values.</p>$$ f_x(z') f(h_x(z'))= E[f(z) | z_s] $$<p>However, how can we calculate the conditional expectations? There are different ways to do this. Let&rsquo;s start with the simplest one. Suppose $x_{\bar{S}}$ denotes the part of original features which are not in the coalition $S$ and $f(x_{\bar{S}}, x_S)$ means that some of the parameters of $f$ belong to $x_S$ and the rest belong to $x_{\bar{S}}$.</p>$$ f_S(x_S) = E[f(x) | x_S] = E[f(x_{\bar{S}}, x_S) | x_S] = \int f(x_{\bar{S}}, x_S) P(x_{\bar{S}} | x_S) dx_{\bar{S}} $$<p>We assume that the features are independent, as we don&rsquo;t know the distribution of the features. Therefore, we can write the above equation as follows:</p>$$ f_S(x_S) = \int f(x_{\bar{S}}, x_S) P(x_{\bar{S}}) dx_{\bar{S}} $$<p>We can approximate this integral with a sum over the a subset of the training samples.</p>$$ f_S(x_S) \approx E[f(x) | x_S] \approx \frac{1}{k} \sum_{i=1}^k f(x_{\bar{S}}^{(i)}, x_S) $$<p>Let&rsquo;s see how this works with an example. Suppose the model is trained on five features ($X_1$ to $X_5$) and the coalition is $S = \{X_1, X_3, X_4\}$. So, $X_{\bar{S}} = \{X_2, X_5\}$. The feature vector $x$ is as follows:</p>$$ x = [x_1, \text{NA}, x_3, x_4, \text{NA}] $$<p>To calculate $f(X)$, we need a value for the <code>NA</code> values. We borrow this value from the training samples. Suppose $i$-th training sample has the following values:</p>$$ x^{(i)} = [x_1^{(i)}, x_2^{(i)}, x_3^{(i)}, x_4^{(i)}, x_5^{(i)}] $$<p>Then, we can calculate the prediction of the model for the sample $x$ as follows:</p>$$ f(x) = f([x_1, x_2^{(i)}, x_3, x_4, x_5^{(i)}]) $$<p>We do this for all selected training samples and take the average of these predictions to calculate the Shapley values.</p><table><thead><tr><th style=text-align:center>Sample</th><th style=text-align:center>$x_1$</th><th style=text-align:center>$x_2$</th><th style=text-align:center>$x_3$</th><th style=text-align:center>$x_4$</th><th style=text-align:center>$x_5$</th><th style=text-align:center>$f(x)$</th></tr></thead><tbody><tr><td style=text-align:center>$1$</td><td style=text-align:center>$x_1^{(1)}$</td><td style=text-align:center>$x_2^{(1)}$</td><td style=text-align:center>$x_3^{(1)}$</td><td style=text-align:center>$x_4^{(1)}$</td><td style=text-align:center>$x_5^{(1)}$</td><td style=text-align:center>$f([x_1, x_2^{(1)}, x_3, x_4, x_5^{(1)}])$</td></tr><tr><td style=text-align:center>$2$</td><td style=text-align:center>$x_1^{(2)}$</td><td style=text-align:center>$x_2^{(2)}$</td><td style=text-align:center>$x_3^{(2)}$</td><td style=text-align:center>$x_4^{(2)}$</td><td style=text-align:center>$x_5^{(2)}$</td><td style=text-align:center>$f([x_1, x_2^{(2)}, x_3, x_4, x_5^{(2)}])$</td></tr><tr><td style=text-align:center>$3$</td><td style=text-align:center>$x_1^{(3)}$</td><td style=text-align:center>$x_2^{(3)}$</td><td style=text-align:center>$x_3^{(3)}$</td><td style=text-align:center>$x_4^{(3)}$</td><td style=text-align:center>$x_5^{(3)}$</td><td style=text-align:center>$f([x_1, x_2^{(3)}, x_3, x_4, x_5^{(3)}])$</td></tr><tr><td style=text-align:center>$\vdots$</td><td style=text-align:center>$\vdots$</td><td style=text-align:center></td><td style=text-align:center>$\vdots$</td><td style=text-align:center>$\vdots$</td><td style=text-align:center></td><td style=text-align:center>$\vdots$</td></tr><tr><td style=text-align:center>$k$</td><td style=text-align:center>$x_1^{(k)}$</td><td style=text-align:center>$x_2^{(k)}$</td><td style=text-align:center>$x_3^{(k)}$</td><td style=text-align:center>$x_4^{(k)}$</td><td style=text-align:center>$x_5^{(k)}$</td><td style=text-align:center>$f([x_1, x_2^{(k)}, x_3, x_4, x_5^{(k)}])$</td></tr><tr><td style=text-align:center>$\text{Average}$</td><td style=text-align:center></td><td style=text-align:center></td><td style=text-align:center></td><td style=text-align:center></td><td style=text-align:center></td><td style=text-align:center>$\frac{1}{k} \sum_{i=1}^k f([x_1, x_2^{(i)}, x_3, x_4, x_5^{(i)})$</td></tr></tbody></table><h3 id=linear-shap-without-dependence>Linear SHAP (without dependence)</h3><p>Suppose the model $f$ is a linear regression model which the features are independent. The prediction of the model can be calculated as follows:</p>$$ f(x) = w_0 + w_1 x_1 + w_2 x_2 + \ldots + w_M x_M = \sum_{i=0}^M w_i x_i \quad x_0 = 1 $$<p>The Shapley value of the feature $X_i$ can be calculated as follows:</p>$$ \phi_i = c_i x_i - c_i \frac{1}{k} \sum_{j=1}^k x_i^{(j)} $$<h3 id=linear-shap-with-dependence>Linear SHAP (with dependence)</h3><p>We can&rsquo;t use the above formula for a linear model with feature dependence. In this case, we should calculate the SHAP values using all the possible coalitions.</p><h3 id=kernel-shap>Kernel SHAP</h3><p>To be continued&mldr; [<a href=#resources>See resources</a>]</p><h3 id=tree-shap>Tree SHAP</h3><p>To be continued&mldr; [<a href=#resources>See resources</a>]</p><h2 id=-resources>üóÇÔ∏è Resources</h2><h3 id=-blog-posts>üì∞ Blog Posts</h3><ul><li><p><a href=https://towardsdatascience.com/introduction-to-shap-values-and-their-application-in-machine-learning-8003718e6827 target=_blank rel=noopener>Introduction to SHAP Values and their Application in Machine Learning</a> by <em>Reza Bagheri</em> on <em>Towards Data Science</em></p></li><li><p><a href=https://hughchen.github.io/its_blog/index.html target=_blank rel=noopener>Understanding Shapley value explanation algorithms for trees</a> by <em>Hugh Chen</em>, <em>Scott Lundberg</em>, and <em>Su-In Lee</em> on <em>GitHub</em></p></li></ul><h3 id=-videos>üéûÔ∏è Videos</h3><ul><li><p><a href="https://youtube.com/playlist?list=PLqDyyww9y-1SJgMw92x90qPYpHgahDLIK&amp;si=2VsAcTTC7GoZc-YC" target=_blank rel=noopener>SHAP playlist</a> by <em>A Data Odyssey</em> on <em>YouTube</em></p></li><li><p><a href="https://youtu.be/VB9uV-x0gtg?si=c6NR2RxH0ZwWUecY" target=_blank rel=noopener>Shapley Additive Explanations (SHAP)</a> by <em>KIE</em></p></li><li><p><a href="https://youtu.be/9haIOplEIGM?si=pr4NplT6vmpoJ9Le" target=_blank rel=noopener>Explainable AI explained! | #4 SHAP</a> by <em>DeepFindr</em></p></li></ul><h3 id=-coding>üë®‚Äçüíª Coding</h3><ul><li><a href=https://shap.readthedocs.io/en/latest/# target=_blank rel=noopener>SHAP library</a> official documentation</li></ul></div><time class="mt-12 mb-8 block text-xs text-gray-500 ltr:text-right rtl:text-left dark:text-gray-400" datetime=2025-01-10T00:00:00.000Z><span>Last updated on</span>
Jan 10, 2025</time><div class="pt-1 no-prose w-full"><hr class="border-dotted border-neutral-300 dark:border-neutral-600"><div class="flex flex-col md:flex-row flex-nowrap justify-between gap-5 pt-2"><div></div><div><a class="group flex text-right no-underline" href=/teaching/nlp/><span class="flex flex-col"><span class="mt-[0.1rem] leading-6 group-hover:underline group-hover:decoration-primary-500">Natural Language Processing</span>
<span class="mt-[0.1rem] text-xs text-neutral-500 dark:text-neutral-400">Nov 1, 2023
</span></span><span class="mt-[-0.3rem] ms-2 text-neutral-700 transition-transform group-hover:-translate-x-[2px] group-hover:text-primary-600 dark:text-neutral dark:group-hover:text-primary-400"><span class=ltr:inline>&rarr;</span></span></a></div></div></div></main></article></div></div><div class=page-footer><footer class="container mx-auto flex flex-col justify-items-center text-sm leading-6 mt-24 mb-4 text-slate-700 dark:text-slate-200"><p class="powered-by text-center">¬© 2025 Me. This work is licensed under <a href=https://creativecommons.org/licenses/by-nc-nd/4.0 rel="noopener noreferrer" target=_blank>CC BY NC ND 4.0</a></p><p class="powered-by footer-license-icons"><a href=https://creativecommons.org/licenses/by-nc-nd/4.0 rel="noopener noreferrer" target=_blank aria-label="Creative Commons"><i class="fab fa-creative-commons fa-2x" aria-hidden=true></i>
<i class="fab fa-creative-commons-by fa-2x" aria-hidden=true></i>
<i class="fab fa-creative-commons-nc fa-2x" aria-hidden=true></i>
<i class="fab fa-creative-commons-nd fa-2x" aria-hidden=true></i></a></p><p class="powered-by text-center">Published with <a href="https://hugoblox.com/?utm_campaign=poweredby" target=_blank rel=noopener>Hugo Blox Builder</a> ‚Äî the free, <a href=https://github.com/HugoBlox/hugo-blox-builder target=_blank rel=noopener>open source</a> website builder that empowers creators.</p></footer></div></body></html>