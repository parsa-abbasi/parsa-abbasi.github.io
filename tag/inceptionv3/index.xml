<?xml version="1.0" encoding="utf-8" standalone="yes"?><rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom"><channel><title>InceptionV3 | Parsa Abbasi</title><link>https://parsa-abbasi.github.io/tag/inceptionv3/</link><atom:link href="https://parsa-abbasi.github.io/tag/inceptionv3/index.xml" rel="self" type="application/rss+xml"/><description>InceptionV3</description><generator>Wowchemy (https://wowchemy.com)</generator><language>en-us</language><lastBuildDate>Wed, 22 Feb 2023 20:15:00 +0000</lastBuildDate><image><url>https://parsa-abbasi.github.io/media/icon_hu14e12911534d82dc6e859b10a3857b5a_3074_512x512_fill_lanczos_center_3.png</url><title>InceptionV3</title><link>https://parsa-abbasi.github.io/tag/inceptionv3/</link></image><item><title>Offline Signature Verification with Convolutional Neural Networks (CNNs)</title><link>https://parsa-abbasi.github.io/project/signature-verification-with-cnn/</link><pubDate>Wed, 22 Feb 2023 20:15:00 +0000</pubDate><guid>https://parsa-abbasi.github.io/project/signature-verification-with-cnn/</guid><description>&lt;p>Signature verification has practical applications in various fields, particularly for security, legal, and financial purposes. Deep learning (DL) models have been proved to be promising in recognizing handwritten signatures, with high accuracy. In this expriment, we investigate the use of the InceptionV3, a pre-trained convolutional neural network (CNN), for signature classification.&lt;/p>
&lt;blockquote>
&lt;p>&lt;strong>Note:&lt;/strong> This project was done as part of the Pattern Recognition course at the Iran University of Science and Technology in the Fall of 2020.&lt;/p>
&lt;/blockquote>
&lt;h2 id="dataset">Dataset&lt;/h2>
&lt;p>The dataset used for this project is called &lt;a href="https://arxiv.org/abs/1603.03235" target="_blank" rel="noopener">UTSig&lt;/a>, which consists of 115 classes, each belonging to one authentic person. There are 27 genuine signatures per class, 3 opposite-hand signed samples, and 42 simple forgeries. The dataset can be downloaded &lt;a href="https://drive.google.com/drive/u/1/folders/0B0CjHfsXJLLObEZFNVdoMlFIODg" target="_blank" rel="noopener">from here&lt;/a>.&lt;/p>
&lt;p>
&lt;figure id="figure-a-sample-of-the-utsig-dataset">
&lt;div class="d-flex justify-content-center">
&lt;div class="w-100" >&lt;img alt="Dataset Sample" srcset="
/project/signature-verification-with-cnn/dataset_sample_hud2377853091e863c5c5001e36e5e225d_46182_d27d914a8dead64a11dc67de0c1fda92.webp 400w,
/project/signature-verification-with-cnn/dataset_sample_hud2377853091e863c5c5001e36e5e225d_46182_e0f789903d398e0e26f10c941a38a26c.webp 760w,
/project/signature-verification-with-cnn/dataset_sample_hud2377853091e863c5c5001e36e5e225d_46182_1200x1200_fit_q75_h2_lanczos_3.webp 1200w"
src="https://parsa-abbasi.github.io/project/signature-verification-with-cnn/dataset_sample_hud2377853091e863c5c5001e36e5e225d_46182_d27d914a8dead64a11dc67de0c1fda92.webp"
width="760"
height="154"
loading="lazy" data-zoomable />&lt;/div>
&lt;/div>&lt;figcaption>
A sample of the UTSig dataset.
&lt;/figcaption>&lt;/figure>
&lt;/p>
&lt;p>To start the implementation, the dataset is downloaded and stored in the Google Drive. The genuine signatures were divided into 22 training images and 5 test images for each person and placed in the appropriate subdirectorie.&lt;/p>
&lt;div class="highlight">&lt;pre tabindex="0" class="chroma">&lt;code class="language-python" data-lang="python">&lt;span class="line">&lt;span class="cl">&lt;span class="err">!&lt;/span>&lt;span class="n">unzip&lt;/span> &lt;span class="s1">&amp;#39;/content/drive/MyDrive/UTSig.zip&amp;#39;&lt;/span>
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/div>&lt;div class="highlight">&lt;pre tabindex="0" class="chroma">&lt;code class="language-python" data-lang="python">&lt;span class="line">&lt;span class="cl">&lt;span class="n">dataset_path&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="s1">&amp;#39;/content/UTSig_Crop/&amp;#39;&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="c1"># Number of genuine signatures per class (person)&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="n">G_num&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="mi">27&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="c1"># Number of forgeries signatures per class (person)&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="n">F_num&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="mi">45&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="c1"># Number of classes (persons)&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="n">c_num&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="mi">115&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="n">os&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">mkdir&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="n">dataset_path&lt;/span> &lt;span class="o">+&lt;/span> &lt;span class="s1">&amp;#39;genuine&amp;#39;&lt;/span>&lt;span class="p">)&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="n">os&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">mkdir&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="n">dataset_path&lt;/span> &lt;span class="o">+&lt;/span> &lt;span class="s1">&amp;#39;genuine/train&amp;#39;&lt;/span>&lt;span class="p">)&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="n">os&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">mkdir&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="n">dataset_path&lt;/span> &lt;span class="o">+&lt;/span> &lt;span class="s1">&amp;#39;genuine/test&amp;#39;&lt;/span>&lt;span class="p">)&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="n">dataset_gen_path&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="n">dataset_path&lt;/span> &lt;span class="o">+&lt;/span> &lt;span class="s1">&amp;#39;genuine/&amp;#39;&lt;/span>
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/div>&lt;h2 id="organizing-the-dataset">Organizing the Dataset&lt;/h2>
&lt;p>We organized the images into the appropriate format for the &lt;code>ImageDataGenerator&lt;/code>. We created subdirectories for each class in the genuine directory, with 22 images for training and 5 images for testing per class.&lt;/p>
&lt;ul>
&lt;li>genuine
&lt;ul>
&lt;li>train
&lt;ul>
&lt;li>class_0
&lt;ul>
&lt;li>0_image_0.png&lt;/li>
&lt;li>0_image_1.png&lt;/li>
&lt;li>&amp;hellip;&lt;/li>
&lt;li>0_image_21.png&lt;/li>
&lt;/ul>
&lt;/li>
&lt;li>class_1&lt;/li>
&lt;li>&amp;hellip;&lt;/li>
&lt;li>class_114&lt;/li>
&lt;/ul>
&lt;/li>
&lt;li>test
&lt;ul>
&lt;li>class_0
&lt;ul>
&lt;li>0_image_22.png&lt;/li>
&lt;li>0_image_23.png&lt;/li>
&lt;li>&amp;hellip;&lt;/li>
&lt;li>0_image_26.png&lt;/li>
&lt;/ul>
&lt;/li>
&lt;li>class_1&lt;/li>
&lt;li>&amp;hellip;&lt;/li>
&lt;li>class_114&lt;/li>
&lt;/ul>
&lt;/li>
&lt;/ul>
&lt;/li>
&lt;/ul>
&lt;div class="highlight">&lt;pre tabindex="0" class="chroma">&lt;code class="language-python" data-lang="python">&lt;span class="line">&lt;span class="cl">&lt;span class="k">for&lt;/span> &lt;span class="n">c&lt;/span> &lt;span class="ow">in&lt;/span> &lt;span class="n">trange&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="n">c_num&lt;/span>&lt;span class="p">):&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="n">class_id&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="n">c&lt;/span> &lt;span class="o">+&lt;/span> &lt;span class="mi">1&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="n">class_id_str&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="nb">str&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="n">class_id&lt;/span>&lt;span class="p">)&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">zfill&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="nb">len&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="nb">str&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="n">c_num&lt;/span>&lt;span class="p">)))&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="c1"># Make a subdirectory for this class&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="n">train_subdirectory&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="n">dataset_gen_path&lt;/span> &lt;span class="o">+&lt;/span> &lt;span class="s1">&amp;#39;/train/class_&amp;#39;&lt;/span> &lt;span class="o">+&lt;/span> &lt;span class="nb">str&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="n">c&lt;/span>&lt;span class="p">)&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="n">os&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">mkdir&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="n">train_subdirectory&lt;/span>&lt;span class="p">)&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="n">test_subdirectory&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="n">dataset_gen_path&lt;/span> &lt;span class="o">+&lt;/span> &lt;span class="s1">&amp;#39;/test/class_&amp;#39;&lt;/span> &lt;span class="o">+&lt;/span> &lt;span class="nb">str&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="n">c&lt;/span>&lt;span class="p">)&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="n">os&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">mkdir&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="n">test_subdirectory&lt;/span>&lt;span class="p">)&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="c1"># For each genuine&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="k">for&lt;/span> &lt;span class="n">g&lt;/span> &lt;span class="ow">in&lt;/span> &lt;span class="nb">range&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="n">G_num&lt;/span>&lt;span class="p">):&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="n">genuine_id&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="n">g&lt;/span> &lt;span class="o">+&lt;/span> &lt;span class="mi">1&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="n">genuine_id_str&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="nb">str&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="n">genuine_id&lt;/span>&lt;span class="p">)&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">zfill&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="nb">len&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="nb">str&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="n">G_num&lt;/span>&lt;span class="p">)))&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="n">file_name&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="s1">&amp;#39;C&amp;#39;&lt;/span> &lt;span class="o">+&lt;/span> &lt;span class="n">class_id_str&lt;/span> &lt;span class="o">+&lt;/span> &lt;span class="s1">&amp;#39;G&amp;#39;&lt;/span> &lt;span class="o">+&lt;/span> &lt;span class="n">genuine_id_str&lt;/span> &lt;span class="o">+&lt;/span> &lt;span class="s1">&amp;#39;.PNG&amp;#39;&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="n">file_path&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="n">dataset_path&lt;/span> &lt;span class="o">+&lt;/span> &lt;span class="n">file_name&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="k">if&lt;/span> &lt;span class="n">g&lt;/span> &lt;span class="o">&amp;lt;&lt;/span> &lt;span class="mi">22&lt;/span>&lt;span class="p">:&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="n">dest_path&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="n">train_subdirectory&lt;/span> &lt;span class="o">+&lt;/span> &lt;span class="s1">&amp;#39;/&amp;#39;&lt;/span> &lt;span class="o">+&lt;/span> &lt;span class="nb">str&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="n">c&lt;/span>&lt;span class="p">)&lt;/span> &lt;span class="o">+&lt;/span> &lt;span class="s1">&amp;#39;_image_&amp;#39;&lt;/span> &lt;span class="o">+&lt;/span> &lt;span class="nb">str&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="n">g&lt;/span>&lt;span class="p">)&lt;/span> &lt;span class="o">+&lt;/span> &lt;span class="s1">&amp;#39;.png&amp;#39;&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="n">os&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">replace&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="n">file_path&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="n">dest_path&lt;/span>&lt;span class="p">)&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="k">else&lt;/span>&lt;span class="p">:&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="n">dest_path&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="n">test_subdirectory&lt;/span> &lt;span class="o">+&lt;/span> &lt;span class="s1">&amp;#39;/&amp;#39;&lt;/span> &lt;span class="o">+&lt;/span> &lt;span class="nb">str&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="n">c&lt;/span>&lt;span class="p">)&lt;/span> &lt;span class="o">+&lt;/span> &lt;span class="s1">&amp;#39;_image_&amp;#39;&lt;/span> &lt;span class="o">+&lt;/span> &lt;span class="nb">str&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="n">g&lt;/span>&lt;span class="p">)&lt;/span> &lt;span class="o">+&lt;/span> &lt;span class="s1">&amp;#39;.png&amp;#39;&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="n">os&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">replace&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="n">file_path&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="n">dest_path&lt;/span>&lt;span class="p">)&lt;/span>
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/div>&lt;h2 id="preprocessing">Preprocessing&lt;/h2>
&lt;p>We used the Image Data Generator from &lt;code>Keras&lt;/code> to preprocess our images. We also applied various augmentation techniques such as rotation, zooming, shifting, and flipping to generate more data and reduce overfitting.&lt;/p>
&lt;div class="highlight">&lt;pre tabindex="0" class="chroma">&lt;code class="language-python" data-lang="python">&lt;span class="line">&lt;span class="cl">&lt;span class="n">src_path_train&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="n">dataset_gen_path&lt;/span> &lt;span class="o">+&lt;/span> &lt;span class="s1">&amp;#39;/train/&amp;#39;&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="n">src_path_test&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="n">dataset_gen_path&lt;/span> &lt;span class="o">+&lt;/span> &lt;span class="s1">&amp;#39;/test/&amp;#39;&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="n">train_datagen&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="n">ImageDataGenerator&lt;/span>&lt;span class="p">(&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="n">rescale&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="mi">1&lt;/span> &lt;span class="o">/&lt;/span> &lt;span class="mf">255.0&lt;/span>&lt;span class="p">,&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="n">rotation_range&lt;/span>&lt;span class="o">=&lt;/span> &lt;span class="mi">20&lt;/span>&lt;span class="p">,&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="n">zoom_range&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="mf">0.05&lt;/span>&lt;span class="p">,&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="n">width_shift_range&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="mf">0.05&lt;/span>&lt;span class="p">,&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="n">height_shift_range&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="mf">0.05&lt;/span>&lt;span class="p">,&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="n">shear_range&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="mf">0.05&lt;/span>&lt;span class="p">,&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="n">horizontal_flip&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="kc">True&lt;/span>&lt;span class="p">,&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="n">fill_mode&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="s2">&amp;#34;nearest&amp;#34;&lt;/span>&lt;span class="p">,&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="n">validation_split&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="mf">0.20&lt;/span>&lt;span class="p">)&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="n">test_datagen&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="n">ImageDataGenerator&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="n">rescale&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="mi">1&lt;/span> &lt;span class="o">/&lt;/span> &lt;span class="mf">255.0&lt;/span>&lt;span class="p">)&lt;/span>
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/div>&lt;div class="highlight">&lt;pre tabindex="0" class="chroma">&lt;code class="language-python" data-lang="python">&lt;span class="line">&lt;span class="cl">&lt;span class="n">batch_size&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="mi">16&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="n">target_size&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="p">(&lt;/span>&lt;span class="mi">299&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">299&lt;/span>&lt;span class="p">)&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="n">train_generator&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="n">train_datagen&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">flow_from_directory&lt;/span>&lt;span class="p">(&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="n">directory&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="n">src_path_train&lt;/span>&lt;span class="p">,&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="n">target_size&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="n">target_size&lt;/span>&lt;span class="p">,&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="n">color_mode&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="s2">&amp;#34;rgb&amp;#34;&lt;/span>&lt;span class="p">,&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="n">batch_size&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="n">batch_size&lt;/span>&lt;span class="p">,&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="n">class_mode&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="s2">&amp;#34;categorical&amp;#34;&lt;/span>&lt;span class="p">,&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="n">subset&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="s1">&amp;#39;training&amp;#39;&lt;/span>&lt;span class="p">,&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="n">shuffle&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="kc">True&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="p">)&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="n">valid_generator&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="n">train_datagen&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">flow_from_directory&lt;/span>&lt;span class="p">(&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="n">directory&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="n">src_path_train&lt;/span>&lt;span class="p">,&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="n">target_size&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="n">target_size&lt;/span>&lt;span class="p">,&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="n">color_mode&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="s2">&amp;#34;rgb&amp;#34;&lt;/span>&lt;span class="p">,&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="n">batch_size&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="n">batch_size&lt;/span>&lt;span class="p">,&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="n">class_mode&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="s2">&amp;#34;categorical&amp;#34;&lt;/span>&lt;span class="p">,&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="n">subset&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="s1">&amp;#39;validation&amp;#39;&lt;/span>&lt;span class="p">,&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="n">shuffle&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="kc">True&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="p">)&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="n">test_generator&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="n">test_datagen&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">flow_from_directory&lt;/span>&lt;span class="p">(&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="n">directory&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="n">src_path_test&lt;/span>&lt;span class="p">,&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="n">target_size&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="n">target_size&lt;/span>&lt;span class="p">,&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="n">color_mode&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="s2">&amp;#34;rgb&amp;#34;&lt;/span>&lt;span class="p">,&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="n">batch_size&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="mi">1&lt;/span>&lt;span class="p">,&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="n">class_mode&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="kc">None&lt;/span>&lt;span class="p">,&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="n">shuffle&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="kc">False&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="p">)&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/div>&lt;div class="highlight">&lt;pre tabindex="0" class="chroma">&lt;code class="language-python" data-lang="python">&lt;span class="line">&lt;span class="cl">&lt;span class="n">test_true_labels&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="n">test_generator&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">classes&lt;/span>
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/div>&lt;h2 id="model">Model&lt;/h2>
&lt;p>
&lt;figure id="figure-the-propsed-model-based-on-inceptionv3">
&lt;div class="d-flex justify-content-center">
&lt;div class="w-100" >&lt;img alt="InceptionV3" srcset="
/project/signature-verification-with-cnn/inception_v3_hu1ba8ba5d6b2f15dda1c844dfebbb3d46_170369_1e61465a65494572c37cd2442b0b08c6.webp 400w,
/project/signature-verification-with-cnn/inception_v3_hu1ba8ba5d6b2f15dda1c844dfebbb3d46_170369_9d810d9e41f217308925202095ea680f.webp 760w,
/project/signature-verification-with-cnn/inception_v3_hu1ba8ba5d6b2f15dda1c844dfebbb3d46_170369_1200x1200_fit_q75_h2_lanczos.webp 1200w"
src="https://parsa-abbasi.github.io/project/signature-verification-with-cnn/inception_v3_hu1ba8ba5d6b2f15dda1c844dfebbb3d46_170369_1e61465a65494572c37cd2442b0b08c6.webp"
width="760"
height="380"
loading="lazy" data-zoomable />&lt;/div>
&lt;/div>&lt;figcaption>
The propsed model based on InceptionV3
&lt;/figcaption>&lt;/figure>
To classify the signatures, we used the &lt;a href="https://keras.io/api/applications/inceptionv3/" target="_blank" rel="noopener">InceptionV3&lt;/a> model, which is pre-trained on the ImageNet database to classify images into 1000 object categories. We modified the model by removing the fully-connected layer at the top, setting all layers to be non-trainable, and adding a 2D Global Average Pooling to transform the feature embedding into a single 2048 size vector. We then added a fully connected layer with 1024 neurons, a Dropout layer, and a softmax layer to calculate the score for each of the classes.&lt;/p>
&lt;div class="highlight">&lt;pre tabindex="0" class="chroma">&lt;code class="language-python" data-lang="python">&lt;span class="line">&lt;span class="cl">&lt;span class="c1"># Loading Inception-V3 model&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="n">model&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="n">InceptionV3&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="n">include_top&lt;/span>&lt;span class="o">=&lt;/span>&lt;span class="kc">False&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="n">weights&lt;/span>&lt;span class="o">=&lt;/span>&lt;span class="s1">&amp;#39;imagenet&amp;#39;&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="n">input_shape&lt;/span>&lt;span class="o">=&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="mi">299&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">299&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">3&lt;/span>&lt;span class="p">))&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="c1"># Freeze layers&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="k">for&lt;/span> &lt;span class="n">layer&lt;/span> &lt;span class="ow">in&lt;/span> &lt;span class="n">model&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">layers&lt;/span>&lt;span class="p">:&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="n">layer&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">trainable&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="kc">False&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="c1"># Add our classifier to the end of the model&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="n">flat1&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="n">GlobalAveragePooling2D&lt;/span>&lt;span class="p">()(&lt;/span>&lt;span class="n">model&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">layers&lt;/span>&lt;span class="p">[&lt;/span>&lt;span class="o">-&lt;/span>&lt;span class="mi">1&lt;/span>&lt;span class="p">]&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">output&lt;/span>&lt;span class="p">)&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="n">class1&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="n">Dense&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="mi">1024&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="n">activation&lt;/span>&lt;span class="o">=&lt;/span>&lt;span class="s1">&amp;#39;relu&amp;#39;&lt;/span>&lt;span class="p">)(&lt;/span>&lt;span class="n">flat1&lt;/span>&lt;span class="p">)&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="n">dropout1&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="n">Dropout&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="mf">0.1&lt;/span>&lt;span class="p">)(&lt;/span>&lt;span class="n">class1&lt;/span>&lt;span class="p">)&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="n">output&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="n">Dense&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="n">c_num&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="n">activation&lt;/span>&lt;span class="o">=&lt;/span>&lt;span class="s1">&amp;#39;softmax&amp;#39;&lt;/span>&lt;span class="p">)(&lt;/span>&lt;span class="n">dropout1&lt;/span>&lt;span class="p">)&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="n">model&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="n">Model&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="n">inputs&lt;/span>&lt;span class="o">=&lt;/span>&lt;span class="n">model&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">inputs&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="n">outputs&lt;/span>&lt;span class="o">=&lt;/span>&lt;span class="n">output&lt;/span>&lt;span class="p">)&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="n">model&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">summary&lt;/span>&lt;span class="p">()&lt;/span>
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/div>&lt;h2 id="training-and-evaluation">Training and Evaluation&lt;/h2>
&lt;p>We trained the model on our preprocessed data for 10 epochs, and the validation accuracy was 87.39%. We evaluated the model on the test set and achieved an accuracy of 89.39% and a weighted F1-score of 89.25%.&lt;/p>
&lt;div class="highlight">&lt;pre tabindex="0" class="chroma">&lt;code class="language-python" data-lang="python">&lt;span class="line">&lt;span class="cl">&lt;span class="c1"># As the problem have multi-class we should use categorical_crossentropy loss function&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="n">model&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">compile&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="n">loss&lt;/span>&lt;span class="o">=&lt;/span>&lt;span class="s1">&amp;#39;categorical_crossentropy&amp;#39;&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="n">optimizer&lt;/span>&lt;span class="o">=&lt;/span>&lt;span class="s1">&amp;#39;adam&amp;#39;&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="n">metrics&lt;/span>&lt;span class="o">=&lt;/span>&lt;span class="p">[&lt;/span>&lt;span class="s1">&amp;#39;accuracy&amp;#39;&lt;/span>&lt;span class="p">])&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="n">STEP_SIZE_TRAIN&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="n">train_generator&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">n&lt;/span>&lt;span class="o">//&lt;/span>&lt;span class="n">train_generator&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">batch_size&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="n">STEP_SIZE_VALID&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="n">valid_generator&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">n&lt;/span>&lt;span class="o">//&lt;/span>&lt;span class="n">valid_generator&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">batch_size&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="n">model_hist&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="n">model&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">fit&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="n">train_generator&lt;/span>&lt;span class="p">,&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="n">steps_per_epoch&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="n">STEP_SIZE_TRAIN&lt;/span>&lt;span class="p">,&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="n">validation_data&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="n">valid_generator&lt;/span>&lt;span class="p">,&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="n">validation_steps&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="n">STEP_SIZE_VALID&lt;/span>&lt;span class="p">,&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="n">epochs&lt;/span>&lt;span class="o">=&lt;/span>&lt;span class="mi">10&lt;/span>&lt;span class="p">)&lt;/span>
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/div>&lt;p>
&lt;figure id="figure-the-learning-curve-of-the-model">
&lt;div class="d-flex justify-content-center">
&lt;div class="w-100" >&lt;img alt="Learning Curve" srcset="
/project/signature-verification-with-cnn/learning_curve_hu8a592860ba336f59abda5517d1fdb7c2_31865_64478ac4d4f3a769157ce4a9cefeca22.webp 400w,
/project/signature-verification-with-cnn/learning_curve_hu8a592860ba336f59abda5517d1fdb7c2_31865_7ea5c9256f1e48c7430280e2029ffb90.webp 760w,
/project/signature-verification-with-cnn/learning_curve_hu8a592860ba336f59abda5517d1fdb7c2_31865_1200x1200_fit_q75_h2_lanczos_3.webp 1200w"
src="https://parsa-abbasi.github.io/project/signature-verification-with-cnn/learning_curve_hu8a592860ba336f59abda5517d1fdb7c2_31865_64478ac4d4f3a769157ce4a9cefeca22.webp"
width="712"
height="352"
loading="lazy" data-zoomable />&lt;/div>
&lt;/div>&lt;figcaption>
The learning curve of the model
&lt;/figcaption>&lt;/figure>
&lt;/p>
&lt;h2 id="classification--unknown-class">Classification + Unknown Class&lt;/h2>
&lt;p>We added a threshold on the softmax results to consider confidence in our predictions. If the maximum softmax value is less than the defined threshold, we classify the image as an unknown class (class_id=115). This was a post-processing step performed after the model&amp;rsquo;s prediction.&lt;/p>
&lt;div class="highlight">&lt;pre tabindex="0" class="chroma">&lt;code class="language-python" data-lang="python">&lt;span class="line">&lt;span class="cl">&lt;span class="n">threshold&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="mf">0.40&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="n">new_pred_classes&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="p">[]&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="k">for&lt;/span> &lt;span class="n">index&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="n">pr&lt;/span> &lt;span class="ow">in&lt;/span> &lt;span class="nb">enumerate&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="n">pred&lt;/span>&lt;span class="p">):&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="k">if&lt;/span> &lt;span class="nb">max&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="n">pr&lt;/span>&lt;span class="p">)&lt;/span> &lt;span class="o">&amp;lt;&lt;/span> &lt;span class="n">threshold&lt;/span>&lt;span class="p">:&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="n">new_pred_classes&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">append&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="mi">115&lt;/span>&lt;span class="p">)&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="k">else&lt;/span>&lt;span class="p">:&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="n">new_pred_classes&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">append&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="n">predicted_class_indices&lt;/span>&lt;span class="p">[&lt;/span>&lt;span class="n">index&lt;/span>&lt;span class="p">])&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="n">new_pred_classes&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="n">np&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">array&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="n">new_pred_classes&lt;/span>&lt;span class="p">)&lt;/span>
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/div>&lt;h2 id="conclusion">Conclusion&lt;/h2>
&lt;p>In conclusion, using a pre-trained model like InceptionV3 for signature classification can yield high accuracy and F1-scores. Preprocessing the data with augmentation techniques can help generate a more robust model and reduce the chance of overfitting.&lt;/p></description></item></channel></rss>